import scrapy
from bs4 import BeautifulSoup
import csv

class ToiSpider(scrapy.Spider):
    name = "toi_spider"
    start_urls = [
        'https://timesofindia.indiatimes.com/home/headlines',
    ]

    def parse(self, response):
        soup = BeautifulSoup(response.body, 'html.parser')
        article_titles = soup.find_all('h2', class_='normal')
        article_links = [a.get('href') for a in soup.find_all('a', class_='title')]
        article_contents = []
        for link in article_links:
            yield response.follow(link, self.parse_article)

    def parse_article(self, response):
        soup = BeautifulSoup(response.body, 'html.parser')
        title = soup.find('h1', class_='title').text.strip()
        content = soup.find('div', class_='Normal').text.strip()
        yield {
            'title': title,
            'content': content,
        }
        with open('toi_articles.csv', 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([title, content])


#also create a .html file to see the output
